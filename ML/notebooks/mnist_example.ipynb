{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf46d903",
   "metadata": {},
   "source": [
    "# MNIST dataset classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d972ff1",
   "metadata": {},
   "source": [
    "## Preliminary operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d83e33e",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eefd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ede00",
   "metadata": {},
   "source": [
    "### Download file and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c219694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-28 08:59:52--  https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "Caricato certificato CA \"/etc/ssl/certs/ca-certificates.crt\"\n",
      "\n",
      "Risoluzione di s3.amazonaws.com (s3.amazonaws.com)... 52.217.229.184\n",
      "Connessione a s3.amazonaws.com (s3.amazonaws.com)|52.217.229.184|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 11490434 (11M) [application/octet-stream]\n",
      "Salvataggio in: «mnist.npz.3»\n",
      "\n",
      "mnist.npz.3         100%[===================>]  10,96M   224KB/s    in 31s     \n",
      "\n",
      "2022-04-28 09:00:24 (361 KB/s) - «mnist.npz.3» salvato [11490434/11490434]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/img-datasets/mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataset is downloaded as .npz file.\n",
    "When an .npz file is loaded with np.load()\n",
    "the result is a dictionary-like object whose\n",
    "elements are acccessible with data[\"label\"].\n",
    "The files attribute returns a list with\n",
    "the possible labels.\n",
    "Example:\n",
    "\n",
    "> data = np.load(\"file.npz\")\n",
    "> print(data.files)\n",
    "\"\"\"\n",
    "\n",
    "def return_ds():\n",
    "    path = \"mnist.npz\"\n",
    "\n",
    "    ds = np.load(path)\n",
    "    print(f\"loaded dataset with labels {ds.files}\\n\\\n",
    "Subsets are returned in the following order:\\n\\\n",
    "x_train, x_test, y_train, y_test\\n\")\n",
    "\n",
    "    return ds[ds.files[1]], ds[ds.files[0]], ds[ds.files[2]], ds[ds.files[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505c021",
   "metadata": {},
   "source": [
    "## With PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf0954",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "709a6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d4ad8",
   "metadata": {},
   "source": [
    "### Normalize data, create dataset, create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "31874cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset with labels ['x_test', 'x_train', 'y_train', 'y_test']\n",
      "Subsets are returned in the following order:\n",
      "x_train, x_test, y_train, y_test\n",
      "\n",
      "Training inputs shape: (60000, 28, 28)\n",
      "Validation inputs shape: (10000, 28, 28)\n",
      "Training outputs shape: (60000,)\n",
      "Validation outputs shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "x_train, x_test, y_train, y_test = return_ds()\n",
    "\n",
    "print(f\"Training inputs shape: {x_train.shape}\")\n",
    "print(f\"Validation inputs shape: {x_test.shape}\")\n",
    "print(f\"Training outputs shape: {y_train.shape}\")\n",
    "print(f\"Validation outputs shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "d8e164e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2679/745248417.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_train, x_test, y_train, y_test = map(\n"
     ]
    }
   ],
   "source": [
    "# Normalize and convert to tensor\n",
    "x_train = (x_train - x_train.mean())/x_train.std()\n",
    "x_test = (x_test - x_test.mean())/x_test.std()\n",
    "\n",
    "x_train, x_test, y_train, y_test = map(\n",
    "                                        torch.tensor,\n",
    "                                        (x_train, x_test, y_train, y_test)\n",
    "                                        )\n",
    "\n",
    "# we need the following when converting from numpy\n",
    "# otherwise pytorch will complain when training a model\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "x_train = x_train.float()\n",
    "x_test = x_test.float()\n",
    "y_train = y_train.long()\n",
    "y_test = y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "abe22073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloader\n",
    "batch_sz = 100\n",
    "\n",
    "cnn_train_ds = TensorDataset(x_train.unsqueeze(1), y_train)\n",
    "cnn_valid_ds = TensorDataset(x_test.unsqueeze(1), y_test)\n",
    "mlp_train_ds = TensorDataset(x_train.reshape(-1, 28*28), y_train)\n",
    "mlp_valid_ds = TensorDataset(x_test.reshape(-1, 28*28), y_test)\n",
    "\n",
    "cnn_train_dl = DataLoader(cnn_train_ds, batch_size=batch_sz, shuffle=True)\n",
    "cnn_valid_dl = DataLoader(cnn_valid_ds, batch_size=batch_sz*4)\n",
    "mlp_train_dl = DataLoader(mlp_train_ds, batch_size=batch_sz, shuffle=True)\n",
    "mlp_valid_dl = DataLoader(mlp_valid_ds, batch_size=batch_sz*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76881a1",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "4f02ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for fitting model and evaluating\n",
    "\n",
    "def step(model: torch.nn.Module,\n",
    "        xb: torch.Tensor,\n",
    "        yb: torch.Tensor,\n",
    "        loss_func: callable,\n",
    "        opt: torch.optim.Optimizer):\n",
    "        \n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def fit(model: torch.nn.Module, \n",
    "        loss_func: callable,\n",
    "        train_dl: torch.utils.data.DataLoader,\n",
    "        val_dl: torch.utils.data.DataLoader,\n",
    "        epochs: int,\n",
    "        opt: torch.optim.Optimizer):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for train_xb, train_yb in train_dl:\n",
    "            loss = step(model, train_xb, train_yb, loss_func, opt)\n",
    "\n",
    "        print(f\"Training loss at epoch {epoch}: {loss:.2f}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for val_xb, val_yb in val_dl:\n",
    "                loss += loss_func(model(val_xb), val_yb)\n",
    "            loss = loss/len(val_dl)\n",
    "            print(f\"Validation loss at epoch {epoch}: {loss:.2f}\\n\")\n",
    "\n",
    "\n",
    "def eval_single_input(model, input):\n",
    "    out = model(input)\n",
    "    return torch.argmax(out)\n",
    "\n",
    "\n",
    "def eval(model, test_x, test_y):\n",
    "    n_success = 0\n",
    "    for n, (x, y) in enumerate(zip(test_x, test_y)):\n",
    "        out_model = eval_single_input(model, x)\n",
    "        n_success += (out_model == y)\n",
    "\n",
    "    return n_success.item()/n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91b0981",
   "metadata": {},
   "source": [
    "### Define and train an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "e14c0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an MLP\n",
    "# might add input and output types to methods of the class\n",
    "# also, arguments that specify how many inputs the network must expect might be good\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 20)\n",
    "        self.layer2 = nn.Linear(20,15)\n",
    "        self.layer3 = nn.Linear(15, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.layer1(input))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        out = self.layer3(x)\n",
    "        # out = F.log_softmax(self.layer3(x), dim = 1) #we use this if we choose nll_loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "e7267c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a cross entropy loss (or a nll loss)\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "# loss_func = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "607039ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model and an optimizer\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "mlp_model = MLP()\n",
    "optim = opt.SGD(mlp_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "db2a6753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2116,  0.3192, -0.2332, -0.1447, -0.1939, -0.0026, -0.1673,  0.1839,\n",
       "         -0.2899, -0.1653]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "IMPORTANT\n",
    "The model expects a rank-2 tensor as input, because the first dimension\n",
    "corresponds to the batch size.\n",
    "\"\"\"\n",
    "\n",
    "# get a batch\n",
    "xb, yb = next(iter(mlp_train_dl))\n",
    "\n",
    "# evaluate loss for this batch\n",
    "loss_func(mlp_model(xb), yb)\n",
    "\n",
    "# compute output for a single element of the batch\n",
    "# note that I need to unsqueeze to get a (1, 784) input to pass to the model\n",
    "mlp_model(xb[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "2674b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0: 0.35\n",
      "Validation loss at epoch 0: 0.29\n",
      "\n",
      "Training loss at epoch 1: 0.20\n",
      "Validation loss at epoch 1: 0.19\n",
      "\n",
      "Training loss at epoch 2: 0.12\n",
      "Validation loss at epoch 2: 0.16\n",
      "\n",
      "Training loss at epoch 3: 0.11\n",
      "Validation loss at epoch 3: 0.16\n",
      "\n",
      "Training loss at epoch 4: 0.26\n",
      "Validation loss at epoch 4: 0.16\n",
      "\n",
      "Training loss at epoch 5: 0.09\n",
      "Validation loss at epoch 5: 0.15\n",
      "\n",
      "Training loss at epoch 6: 0.13\n",
      "Validation loss at epoch 6: 0.15\n",
      "\n",
      "Training loss at epoch 7: 0.13\n",
      "Validation loss at epoch 7: 0.15\n",
      "\n",
      "Training loss at epoch 8: 0.06\n",
      "Validation loss at epoch 8: 0.14\n",
      "\n",
      "Training loss at epoch 9: 0.08\n",
      "Validation loss at epoch 9: 0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "n_epochs = 10\n",
    "\n",
    "fit(mlp_model, loss_func, mlp_train_dl, mlp_valid_dl, n_epochs, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "1e9cd0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb500861c30>"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = x_test[104]\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "f96f23a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This digit is a 9 according to my model.\n"
     ]
    }
   ],
   "source": [
    "print(f\"This digit is a \\\n",
    "{eval_single_input(mlp_model, im.view(-1, 28*28)).item()} \\\n",
    "according to my model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "b6f57a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy over validation set: 95.92%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation accuracy over validation set: \\\n",
    "{eval(mlp_model, x_test.view(-1, 784), y_test.view(-1,1))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f341d",
   "metadata": {},
   "source": [
    "### Define and train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "fcbfb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a CNN\n",
    "# using several channels internally noticeably improves performance (obviously training slows down)\n",
    "\n",
    "# might add input and output types to methods of the class\n",
    "# also, arguments that specify how many inputs the network must expect might be good\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 12, kernel_size=4, padding=(2,2), padding_mode=\"zeros\")\n",
    "        self.conv2 = nn.Conv2d(12, 9, kernel_size=3, padding=(1,1), padding_mode=\"zeros\")\n",
    "        self.conv3 = nn.Conv2d(9, 9, kernel_size=3, padding=(1,1), padding_mode=\"zeros\")\n",
    "        self.dense1 = nn.Linear(49*9, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.conv1(input))\n",
    "        x = F.avg_pool2d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.avg_pool2d(x, kernel_size=2)\n",
    "        x = x.reshape(-1, 49*9)\n",
    "        out = self.dense1(x)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "204cac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a loss\n",
    "\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "bd83bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model and optimizer\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "cnn_model = CNN()\n",
    "optim = opt.SGD(cnn_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "b436b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb has shape torch.Size([100, 1, 28, 28])\n",
      "\n",
      "sample from xb has shape torch.Size([1, 1, 28, 28])\n",
      "\n",
      "Output from a batch sample: tensor([[-0.0180, -0.0129, -0.0721,  0.0545, -0.0266, -0.0892,  0.0764, -0.0102,\n",
      "          0.1069,  0.0263]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xb, yb = next(iter(cnn_train_dl))\n",
    "sample = xb[0].unsqueeze(0)\n",
    "\n",
    "print(f\"xb has shape {xb.shape}\\n\")\n",
    "print(f\"sample from xb has shape {sample.shape}\\n\")\n",
    "\n",
    "print(f\"Output from a batch sample: {cnn_model(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "295ffffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0: 0.13\n",
      "Validation loss at epoch 0: 0.12\n",
      "\n",
      "Training loss at epoch 1: 0.34\n",
      "Validation loss at epoch 1: 0.08\n",
      "\n",
      "Training loss at epoch 2: 0.05\n",
      "Validation loss at epoch 2: 0.06\n",
      "\n",
      "Training loss at epoch 3: 0.12\n",
      "Validation loss at epoch 3: 0.06\n",
      "\n",
      "Training loss at epoch 4: 0.04\n",
      "Validation loss at epoch 4: 0.05\n",
      "\n",
      "Training loss at epoch 5: 0.03\n",
      "Validation loss at epoch 5: 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 6\n",
    "\n",
    "fit(cnn_model, loss_func, cnn_train_dl, cnn_valid_dl, n_epochs, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "c029316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy over validation set: 98.40%\n"
     ]
    }
   ],
   "source": [
    "x_samples = x_test.unsqueeze(1).unsqueeze(1)\n",
    "y_samples = y_test.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "print(f\"Validation accuracy over validation set: \\\n",
    "{eval(cnn_model, x_samples, y_samples)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
