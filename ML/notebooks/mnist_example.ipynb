{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf46d903",
   "metadata": {},
   "source": [
    "# MNIST dataset classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cf0954",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709a6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d4ad8",
   "metadata": {},
   "source": [
    "### Normalize data, create dataset, create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c219694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-28 08:59:52--  https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "Caricato certificato CA \"/etc/ssl/certs/ca-certificates.crt\"\n",
      "\n",
      "Risoluzione di s3.amazonaws.com (s3.amazonaws.com)... 52.217.229.184\n",
      "Connessione a s3.amazonaws.com (s3.amazonaws.com)|52.217.229.184|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 11490434 (11M) [application/octet-stream]\n",
      "Salvataggio in: «mnist.npz.3»\n",
      "\n",
      "mnist.npz.3         100%[===================>]  10,96M   224KB/s    in 31s     \n",
      "\n",
      "2022-04-28 09:00:24 (361 KB/s) - «mnist.npz.3» salvato [11490434/11490434]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/img-datasets/mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cfa1a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataset is downloaded as .npz file.\n",
    "When an .npz file is loaded with np.load()\n",
    "the result is a dictionary-like object whose\n",
    "elements are acccessible with data[\"label\"].\n",
    "The files attribute returns a list with\n",
    "the possible labels.\n",
    "Example:\n",
    "\n",
    "> data = np.load(\"file.npz\")\n",
    "> print(data.files)\n",
    "\"\"\"\n",
    "\n",
    "def return_ds():\n",
    "    path = \"mnist.npz\"\n",
    "\n",
    "    ds = np.load(path)\n",
    "    print(f\"loaded dataset with labels {ds.files}\\n\\\n",
    "Subsets are returned in the following order:\\n\\\n",
    "x_train, x_test, y_train, y_test\\n\")\n",
    "\n",
    "    return ds[ds.files[1]], ds[ds.files[0]], ds[ds.files[2]], ds[ds.files[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31874cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset with labels ['x_test', 'x_train', 'y_train', 'y_test']\n",
      "Subsets are returned in the following order:\n",
      "x_train, x_test, y_train, y_test\n",
      "\n",
      "Training inputs shape: (60000, 28, 28)\n",
      "Validation inputs shape: (10000, 28, 28)\n",
      "Training outputs shape: (60000,)\n",
      "Validation outputs shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "x_train, x_test, y_train, y_test = return_ds()\n",
    "\n",
    "print(f\"Training inputs shape: {x_train.shape}\")\n",
    "print(f\"Validation inputs shape: {x_test.shape}\")\n",
    "print(f\"Training outputs shape: {y_train.shape}\")\n",
    "print(f\"Validation outputs shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d8e164e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and convert to tensor\n",
    "x_train = (x_train - x_train.mean())/x_train.std()\n",
    "x_test = (x_test - x_test.mean())/x_test.std()\n",
    "\n",
    "x_train, x_test, y_train, y_test = map(\n",
    "                                        torch.tensor,\n",
    "                                        (x_train, x_test, y_train, y_test)\n",
    "                                        )\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "x_train = x_train.float()\n",
    "x_test = x_test.float()\n",
    "y_train = y_train.long()\n",
    "y_test = y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "abe22073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloader\n",
    "batch_sz = 100\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_test, y_test)\n",
    "mlp_train_ds = TensorDataset(x_train.reshape(-1, 28*28), y_train)\n",
    "mlp_valid_ds = TensorDataset(x_test.reshape(-1, 28*28), y_test)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_sz, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_sz*4)\n",
    "mlp_train_dl = DataLoader(mlp_train_ds, batch_size=batch_sz, shuffle=True)\n",
    "mlp_valid_dl = DataLoader(mlp_valid_ds, batch_size=batch_sz*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "88f42b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.reshape(-1, 28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e14c0ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 20)\n",
    "        self.layer2 = nn.Linear(20,15)\n",
    "        self.layer3 = nn.Linear(15, 10)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.layer1(input))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a cross entropy loss (or an mse loss)\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "# loss_func = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4f02ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for fitting model and evaluating\n",
    "\n",
    "def step(model, xb, yb, loss_func, opt):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def fit(model, loss_func, train_dl, val_dl, epochs, opt):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for train_xb, train_yb in train_dl:\n",
    "            loss = step(model, train_xb, train_yb, loss_func, opt)\n",
    "\n",
    "        print(f\"Training loss at epoch {epoch}: {loss:.2f}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for val_xb, val_yb in val_dl:\n",
    "                loss += loss_func(model(val_xb), val_yb)\n",
    "            loss = loss/len(val_dl)\n",
    "            print(f\"Validation loss at epoch {epoch}: {loss:.2f}\\n\")\n",
    "\n",
    "\n",
    "def eval_single_input(model, input):\n",
    "    out = model(input)\n",
    "    return torch.argmax(out)\n",
    "\n",
    "\n",
    "def eval(model, x_test, y_test):\n",
    "    n_success = 0\n",
    "    for n, (x, y) in enumerate(zip(x_test, y_test)):\n",
    "        out_model = eval_single_input(model, x)\n",
    "        n_success += (out_model == y)\n",
    "\n",
    "    return n_success/n\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "607039ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model and an optimizer\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "mlp_model = MLP()\n",
    "optim = opt.SGD(mlp_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2674b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0: 0.16\n",
      "Validation loss at epoch 0: 0.24\n",
      "\n",
      "Training loss at epoch 1: 0.20\n",
      "Validation loss at epoch 1: 0.18\n",
      "\n",
      "Training loss at epoch 2: 0.20\n",
      "Validation loss at epoch 2: 0.16\n",
      "\n",
      "Training loss at epoch 3: 0.07\n",
      "Validation loss at epoch 3: 0.15\n",
      "\n",
      "Training loss at epoch 4: 0.11\n",
      "Validation loss at epoch 4: 0.16\n",
      "\n",
      "Training loss at epoch 5: 0.13\n",
      "Validation loss at epoch 5: 0.14\n",
      "\n",
      "Training loss at epoch 6: 0.14\n",
      "Validation loss at epoch 6: 0.16\n",
      "\n",
      "Training loss at epoch 7: 0.18\n",
      "Validation loss at epoch 7: 0.14\n",
      "\n",
      "Training loss at epoch 8: 0.09\n",
      "Validation loss at epoch 8: 0.14\n",
      "\n",
      "Training loss at epoch 9: 0.08\n",
      "Validation loss at epoch 9: 0.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "fit(mlp_model, loss_func, mlp_train_dl, mlp_valid_dl, 10, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1e9cd0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb5143dff10>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = x_test[0]\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f96f23a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_single_input(mlp_model, im.view(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b6f57a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9592])\n"
     ]
    }
   ],
   "source": [
    "print(eval(mlp_model, x_test.view(10000, -1), y_test.view(10000, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e07bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
